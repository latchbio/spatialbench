{
  "metadata": {
    "benchmark_version": "2.0",
    "n_evaluations": 146,
    "n_runs_per_model": 3,
    "date": "2025-12-21",
    "ci_method": "t-distribution based, 95% confidence, computed over per-evaluation means"
  },
  "models": [
    {
      "id": "opus-4-5-claude-code",
      "display_name": "Claude Opus 4.5 (Claude Code)",
      "provider": "Anthropic",
      "harness": "claude-code",
      "accuracy": {"mean": 48.1, "ci_lower": 40.8, "ci_upper": 55.3},
      "time_s": {"mean": 274.7, "ci_lower": 217.1, "ci_upper": 332.4},
      "cost_usd": {"mean": 0.388, "ci_lower": 0.349, "ci_upper": 0.428}
    },
    {
      "id": "sonnet-4-5-claude-code",
      "display_name": "Claude Sonnet 4.5 (Claude Code)",
      "provider": "Anthropic",
      "harness": "claude-code",
      "accuracy": {"mean": 45.1, "ci_lower": 38.0, "ci_upper": 52.2},
      "time_s": {"mean": 285.3, "ci_lower": 219.5, "ci_upper": 351.1},
      "cost_usd": {"mean": 0.386, "ci_lower": 0.347, "ci_upper": 0.426}
    },
    {
      "id": "opus-4-5",
      "display_name": "Claude Opus 4.5",
      "provider": "Anthropic",
      "harness": "mini-swe-agent",
      "accuracy": {"mean": 38.4, "ci_lower": 31.3, "ci_upper": 45.4},
      "steps": {"mean": 2.8, "ci_lower": 2.5, "ci_upper": 3.2},
      "time_s": {"mean": 123.8, "ci_lower": 104.8, "ci_upper": 142.9},
      "cost_usd": {"mean": 0.143, "ci_lower": 0.121, "ci_upper": 0.165}
    },
    {
      "id": "gpt-5-2",
      "display_name": "GPT-5.2",
      "provider": "OpenAI",
      "harness": "mini-swe-agent",
      "accuracy": {"mean": 34.0, "ci_lower": 27.6, "ci_upper": 40.5},
      "steps": {"mean": 2.1, "ci_lower": 1.9, "ci_upper": 2.3},
      "time_s": {"mean": 89.2, "ci_lower": 76.9, "ci_upper": 101.4},
      "cost_usd": {"mean": 0.036, "ci_lower": 0.031, "ci_upper": 0.042}
    },
    {
      "id": "sonnet-4-5",
      "display_name": "Claude Sonnet 4.5",
      "provider": "Anthropic",
      "harness": "mini-swe-agent",
      "accuracy": {"mean": 28.3, "ci_lower": 22.2, "ci_upper": 34.4},
      "steps": {"mean": 2.4, "ci_lower": 2.2, "ci_upper": 2.7},
      "time_s": {"mean": 115.6, "ci_lower": 98.0, "ci_upper": 133.2},
      "cost_usd": {"mean": 0.080, "ci_lower": 0.068, "ci_upper": 0.093}
    },
    {
      "id": "gpt-5-1",
      "display_name": "GPT-5.1",
      "provider": "OpenAI",
      "harness": "mini-swe-agent",
      "accuracy": {"mean": 27.4, "ci_lower": 21.3, "ci_upper": 33.5},
      "steps": {"mean": 2.4, "ci_lower": 2.2, "ci_upper": 2.6},
      "time_s": {"mean": 55.8, "ci_lower": 48.2, "ci_upper": 63.5},
      "cost_usd": {"mean": 0.020, "ci_lower": 0.017, "ci_upper": 0.023}
    },
    {
      "id": "grok-4-1-fast-reasoning",
      "display_name": "Grok-4.1 Fast Reasoning",
      "provider": "xAI",
      "harness": "mini-swe-agent",
      "accuracy": {"mean": 24.7, "ci_lower": 19.8, "ci_upper": 29.5},
      "steps": {"mean": 9.9, "ci_lower": 8.1, "ci_upper": 11.8},
      "time_s": {"mean": 196.4, "ci_lower": 175.4, "ci_upper": 217.3},
      "cost_usd": {"mean": 0.077, "ci_lower": 0.047, "ci_upper": 0.107}
    },
    {
      "id": "grok-4-fast-reasoning",
      "display_name": "Grok-4 Fast Reasoning",
      "provider": "xAI",
      "harness": "mini-swe-agent",
      "accuracy": {"mean": 22.8, "ci_lower": 17.7, "ci_upper": 28.0},
      "steps": {"mean": 9.9, "ci_lower": 7.7, "ci_upper": 12.1},
      "time_s": {"mean": 173.2, "ci_lower": 148.0, "ci_upper": 198.3},
      "cost_usd": {"mean": 0.048, "ci_lower": 0.030, "ci_upper": 0.067}
    },
    {
      "id": "gemini-2.5-pro",
      "display_name": "Gemini 2.5 Pro",
      "provider": "Google",
      "harness": "mini-swe-agent",
      "accuracy": {"mean": 20.1, "ci_lower": 14.8, "ci_upper": 25.4},
      "steps": {"mean": 3.6, "ci_lower": 3.1, "ci_upper": 4.1},
      "time_s": {"mean": 193.5, "ci_lower": 168.2, "ci_upper": 218.7},
      "cost_usd": {"mean": 0.188, "ci_lower": 0.157, "ci_upper": 0.219}
    }
  ],
  "by_task": {
    "normalization": {
      "n_evals": 7,
      "results": [
        {"model": "gpt-5-2", "accuracy": 76.2},
        {"model": "sonnet-4-5", "accuracy": 71.4},
        {"model": "gemini-2.5-pro", "accuracy": 66.7},
        {"model": "grok-4-fast-reasoning", "accuracy": 66.7},
        {"model": "opus-4-5", "accuracy": 61.9},
        {"model": "sonnet-4-5-claude-code", "accuracy": 61.9},
        {"model": "grok-4-1-fast-reasoning", "accuracy": 61.9},
        {"model": "gpt-5-1", "accuracy": 52.4},
        {"model": "opus-4-5-claude-code", "accuracy": 52.4}
      ]
    },
    "dimensionality_reduction": {
      "n_evals": 15,
      "results": [
        {"model": "sonnet-4-5-claude-code", "accuracy": 63.3},
        {"model": "opus-4-5-claude-code", "accuracy": 62.2},
        {"model": "sonnet-4-5", "accuracy": 53.3},
        {"model": "opus-4-5", "accuracy": 51.1},
        {"model": "gpt-5-2", "accuracy": 46.7},
        {"model": "gpt-5-1", "accuracy": 37.8},
        {"model": "grok-4-1-fast-reasoning", "accuracy": 33.3},
        {"model": "grok-4-fast-reasoning", "accuracy": 26.7},
        {"model": "gemini-2.5-pro", "accuracy": 24.4}
      ]
    },
    "spatial_analysis": {
      "n_evals": 17,
      "results": [
        {"model": "opus-4-5-claude-code", "accuracy": 66.7},
        {"model": "sonnet-4-5-claude-code", "accuracy": 56.9},
        {"model": "opus-4-5", "accuracy": 52.9},
        {"model": "gpt-5-2", "accuracy": 45.1},
        {"model": "gpt-5-1", "accuracy": 43.1},
        {"model": "sonnet-4-5", "accuracy": 41.2},
        {"model": "grok-4-fast-reasoning", "accuracy": 31.4},
        {"model": "grok-4-1-fast-reasoning", "accuracy": 31.4},
        {"model": "gemini-2.5-pro", "accuracy": 9.8}
      ]
    },
    "clustering": {
      "n_evals": 21,
      "results": [
        {"model": "opus-4-5-claude-code", "accuracy": 60.3},
        {"model": "sonnet-4-5-claude-code", "accuracy": 50.8},
        {"model": "opus-4-5", "accuracy": 33.3},
        {"model": "gpt-5-2", "accuracy": 33.3},
        {"model": "grok-4-fast-reasoning", "accuracy": 23.8},
        {"model": "gpt-5-1", "accuracy": 20.6},
        {"model": "grok-4-1-fast-reasoning", "accuracy": 20.6},
        {"model": "sonnet-4-5", "accuracy": 17.5},
        {"model": "gemini-2.5-pro", "accuracy": 17.5}
      ]
    },
    "cell_typing": {
      "n_evals": 39,
      "results": [
        {"model": "opus-4-5-claude-code", "accuracy": 38.9},
        {"model": "sonnet-4-5-claude-code", "accuracy": 38.5},
        {"model": "opus-4-5", "accuracy": 35.9},
        {"model": "gpt-5-2", "accuracy": 32.5},
        {"model": "gpt-5-1", "accuracy": 22.2},
        {"model": "sonnet-4-5", "accuracy": 21.4},
        {"model": "grok-4-1-fast-reasoning", "accuracy": 21.4},
        {"model": "gemini-2.5-pro", "accuracy": 20.5},
        {"model": "grok-4-fast-reasoning", "accuracy": 19.7}
      ]
    },
    "differential_expression": {
      "n_evals": 26,
      "results": [
        {"model": "opus-4-5-claude-code", "accuracy": 46.2},
        {"model": "sonnet-4-5-claude-code", "accuracy": 43.6},
        {"model": "opus-4-5", "accuracy": 37.2},
        {"model": "gpt-5-1", "accuracy": 30.8},
        {"model": "gpt-5-2", "accuracy": 30.8},
        {"model": "sonnet-4-5", "accuracy": 28.2},
        {"model": "grok-4-1-fast-reasoning", "accuracy": 23.1},
        {"model": "grok-4-fast-reasoning", "accuracy": 17.9},
        {"model": "gemini-2.5-pro", "accuracy": 16.7}
      ]
    },
    "qc": {
      "n_evals": 20,
      "results": [
        {"model": "opus-4-5-claude-code", "accuracy": 30.0},
        {"model": "sonnet-4-5-claude-code", "accuracy": 26.7},
        {"model": "opus-4-5", "accuracy": 21.7},
        {"model": "gemini-2.5-pro", "accuracy": 16.7},
        {"model": "grok-4-1-fast-reasoning", "accuracy": 13.3},
        {"model": "gpt-5-1", "accuracy": 11.7},
        {"model": "sonnet-4-5", "accuracy": 10.0},
        {"model": "gpt-5-2", "accuracy": 10.0},
        {"model": "grok-4-fast-reasoning", "accuracy": 10.0}
      ]
    }
  },
  "by_platform": {
    "merfish": {
      "n_evals": 18,
      "results": [
        {"model": "opus-4-5-claude-code", "accuracy": 57.4},
        {"model": "sonnet-4-5-claude-code", "accuracy": 48.1},
        {"model": "opus-4-5", "accuracy": 42.6},
        {"model": "gpt-5-2", "accuracy": 33.3},
        {"model": "grok-4-1-fast-reasoning", "accuracy": 27.8},
        {"model": "sonnet-4-5", "accuracy": 25.9},
        {"model": "gpt-5-1", "accuracy": 24.1},
        {"model": "grok-4-fast-reasoning", "accuracy": 24.1},
        {"model": "gemini-2.5-pro", "accuracy": 13.0}
      ]
    },
    "visium": {
      "n_evals": 32,
      "results": [
        {"model": "opus-4-5-claude-code", "accuracy": 52.6},
        {"model": "sonnet-4-5-claude-code", "accuracy": 44.8},
        {"model": "opus-4-5", "accuracy": 39.6},
        {"model": "gpt-5-2", "accuracy": 30.2},
        {"model": "gpt-5-1", "accuracy": 26.0},
        {"model": "grok-4-1-fast-reasoning", "accuracy": 26.0},
        {"model": "sonnet-4-5", "accuracy": 24.0},
        {"model": "grok-4-fast-reasoning", "accuracy": 22.9},
        {"model": "gemini-2.5-pro", "accuracy": 20.8}
      ]
    },
    "atlasxomics": {
      "n_evals": 23,
      "results": [
        {"model": "opus-4-5-claude-code", "accuracy": 50.7},
        {"model": "sonnet-4-5-claude-code", "accuracy": 50.7},
        {"model": "opus-4-5", "accuracy": 43.5},
        {"model": "gpt-5-2", "accuracy": 37.7},
        {"model": "sonnet-4-5", "accuracy": 29.0},
        {"model": "gpt-5-1", "accuracy": 27.5},
        {"model": "grok-4-1-fast-reasoning", "accuracy": 24.6},
        {"model": "grok-4-fast-reasoning", "accuracy": 23.2},
        {"model": "gemini-2.5-pro", "accuracy": 21.7}
      ]
    },
    "xenium": {
      "n_evals": 30,
      "results": [
        {"model": "sonnet-4-5-claude-code", "accuracy": 52.2},
        {"model": "opus-4-5-claude-code", "accuracy": 48.9},
        {"model": "opus-4-5", "accuracy": 45.6},
        {"model": "gpt-5-2", "accuracy": 40.0},
        {"model": "sonnet-4-5", "accuracy": 38.9},
        {"model": "gpt-5-1", "accuracy": 33.3},
        {"model": "grok-4-fast-reasoning", "accuracy": 26.7},
        {"model": "grok-4-1-fast-reasoning", "accuracy": 26.7},
        {"model": "gemini-2.5-pro", "accuracy": 21.1}
      ]
    },
    "seeker": {
      "n_evals": 43,
      "results": [
        {"model": "opus-4-5-claude-code", "accuracy": 38.8},
        {"model": "sonnet-4-5-claude-code", "accuracy": 36.0},
        {"model": "gpt-5-2", "accuracy": 31.0},
        {"model": "opus-4-5", "accuracy": 27.9},
        {"model": "gpt-5-1", "accuracy": 25.6},
        {"model": "sonnet-4-5", "accuracy": 24.8},
        {"model": "gemini-2.5-pro", "accuracy": 20.9},
        {"model": "grok-4-1-fast-reasoning", "accuracy": 20.9},
        {"model": "grok-4-fast-reasoning", "accuracy": 19.4}
      ]
    }
  }
}
